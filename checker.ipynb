{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 检查强化学习控制器model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------- 来自于mujoco150在win+py3.9下的矫情的要求 --------\n",
    "# 手动添加mujoco路径\n",
    "import os\n",
    "from getpass import getuser\n",
    "user_id = getuser()\n",
    "os.add_dll_directory(f\"C://Users//{user_id}//.mujoco//mujoco200//bin\")\n",
    "os.add_dll_directory(f\"C://Users//{user_id}//.mujoco//mujoco-py-2.0.2.0//mujoco_py\")\n",
    "# -------------------------------------------------------\n",
    "import time\n",
    "import argparse\n",
    "import sys\n",
    "import gym_custom_env       # 注册自定义环境\n",
    "import gym\n",
    "import numpy as np\n",
    "import pybullet_envs\n",
    "from stable_baselines3 import SAC, TD3, PPO\n",
    "from mujoco_py.generated import const\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============ HUMANOID CUSTOM ENV ============\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('HumanoidCustomEnv-v0')\n",
    "#env.render(mode=\"human\")\n",
    "save_path = \"sb3model/HumanoidCustomEnv-v0/2e6_t4_sac_HumanoidCustomEnv-v0/best_model.zip\"\n",
    "\n",
    "sac_model = SAC.load(save_path, env=env)\n",
    "ppo_model = PPO.load('sb3model/HumanoidCustomEnv-v0/2e7_t10_cpu6_ppo_HumanoidCustomEnv-v0/best_model.zip',env=env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SACPolicy(\n",
       "  (actor): Actor(\n",
       "    (features_extractor): FlattenExtractor(\n",
       "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "    )\n",
       "    (latent_pi): Sequential(\n",
       "      (0): Linear(in_features=294, out_features=256, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (3): ReLU()\n",
       "    )\n",
       "    (mu): Linear(in_features=256, out_features=17, bias=True)\n",
       "    (log_std): Linear(in_features=256, out_features=17, bias=True)\n",
       "  )\n",
       "  (critic): ContinuousCritic(\n",
       "    (features_extractor): FlattenExtractor(\n",
       "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "    )\n",
       "    (qf0): Sequential(\n",
       "      (0): Linear(in_features=311, out_features=256, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=256, out_features=1, bias=True)\n",
       "    )\n",
       "    (qf1): Sequential(\n",
       "      (0): Linear(in_features=311, out_features=256, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=256, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (critic_target): ContinuousCritic(\n",
       "    (features_extractor): FlattenExtractor(\n",
       "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "    )\n",
       "    (qf0): Sequential(\n",
       "      (0): Linear(in_features=311, out_features=256, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=256, out_features=1, bias=True)\n",
       "    )\n",
       "    (qf1): Sequential(\n",
       "      (0): Linear(in_features=311, out_features=256, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=256, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 手动设置policy_kwargs=dict(net_arch=[256, 256])的sac策略网络\n",
    "sac_model.policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ActorCriticPolicy(\n",
       "  (features_extractor): FlattenExtractor(\n",
       "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  )\n",
       "  (mlp_extractor): MlpExtractor(\n",
       "    (shared_net): Sequential(\n",
       "      (0): Linear(in_features=294, out_features=256, bias=True)\n",
       "      (1): Tanh()\n",
       "      (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (3): Tanh()\n",
       "    )\n",
       "    (policy_net): Sequential()\n",
       "    (value_net): Sequential()\n",
       "  )\n",
       "  (action_net): Linear(in_features=256, out_features=17, bias=True)\n",
       "  (value_net): Linear(in_features=256, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 手动设置policy_kwargs=dict(net_arch=[256, 256])的PPO策略网络\n",
    "ppo_model.policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ActorCriticPolicy(\n",
       "  (features_extractor): FlattenExtractor(\n",
       "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  )\n",
       "  (mlp_extractor): MlpExtractor(\n",
       "    (shared_net): Sequential()\n",
       "    (policy_net): Sequential(\n",
       "      (0): Linear(in_features=294, out_features=64, bias=True)\n",
       "      (1): Tanh()\n",
       "      (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (3): Tanh()\n",
       "    )\n",
       "    (value_net): Sequential(\n",
       "      (0): Linear(in_features=294, out_features=64, bias=True)\n",
       "      (1): Tanh()\n",
       "      (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (3): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (action_net): Linear(in_features=64, out_features=17, bias=True)\n",
       "  (value_net): Linear(in_features=64, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PPO的默认策略网络\n",
    "default_ppo_model = PPO.load('sb3model/HumanoidCustomEnv-v0/2e6_t4_ppo_HumanoidCustomEnv-v0.zip',env=env)\n",
    "default_ppo_model.policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SACPolicy(\n",
       "  (actor): Actor(\n",
       "    (features_extractor): FlattenExtractor(\n",
       "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "    )\n",
       "    (latent_pi): Sequential(\n",
       "      (0): Linear(in_features=294, out_features=256, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (3): ReLU()\n",
       "    )\n",
       "    (mu): Linear(in_features=256, out_features=17, bias=True)\n",
       "    (log_std): Linear(in_features=256, out_features=17, bias=True)\n",
       "  )\n",
       "  (critic): ContinuousCritic(\n",
       "    (features_extractor): FlattenExtractor(\n",
       "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "    )\n",
       "    (qf0): Sequential(\n",
       "      (0): Linear(in_features=311, out_features=256, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=256, out_features=1, bias=True)\n",
       "    )\n",
       "    (qf1): Sequential(\n",
       "      (0): Linear(in_features=311, out_features=256, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=256, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (critic_target): ContinuousCritic(\n",
       "    (features_extractor): FlattenExtractor(\n",
       "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "    )\n",
       "    (qf0): Sequential(\n",
       "      (0): Linear(in_features=311, out_features=256, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=256, out_features=1, bias=True)\n",
       "    )\n",
       "    (qf1): Sequential(\n",
       "      (0): Linear(in_features=311, out_features=256, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=256, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SAC的默认策略网络\n",
    "default_sac_model = SAC.load('sb3model/HumanoidCustomEnv-v0/2e6_t0_sac_HumanoidCustomEnv-v0.zip',env=env)\n",
    "default_sac_model.policy\n",
    "default_sac_model.predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial.transform import Rotation as R\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.27460000000151463\n",
      "[-3.50e-01  1.23e-06  4.18e-08  3.90e-01]\n",
      "[[ 1.00000000e+00 -3.25420248e-06  3.38725419e-06]\n",
      " [-3.01673707e-06  1.07793154e-01  9.94173343e-01]\n",
      " [-3.60036417e-06 -9.94173343e-01  1.07793154e-01]]\n",
      "[3.38725419e-06 9.94173343e-01 1.07793154e-01]\n",
      "1.0\n",
      "0.10779315367197961\n"
     ]
    }
   ],
   "source": [
    "pos = np.array([0 , 1, 0, -0.35, 1.23e-06, 4.18e-08, 0.39,1,2])\n",
    "quatanion = pos[3:7]\n",
    "sum = np.linalg.norm(quatanion)\n",
    "print(np.sum(quatanion*quatanion))\n",
    "print(quatanion)\n",
    "Rm = R.from_quat(quatanion)  # Rotation matrix\n",
    "rotation_matrix = Rm.as_matrix()\n",
    "print(rotation_matrix)\n",
    "vertical_direction = np.array([0, 0, 1])\n",
    "body_z_axis = rotation_matrix.dot(vertical_direction)\n",
    "print(body_z_axis)\n",
    "sum = np.linalg.norm(body_z_axis)\n",
    "print(sum)\n",
    "# 计算z轴方向向量与竖直向上方向向量的点积\n",
    "dot_product = np.dot(body_z_axis, vertical_direction)\n",
    "print(dot_product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "def sumA(a,b):\n",
    "    return a*2+b\n",
    "def sumB(a,b):\n",
    "    return a+b*3\n",
    "class A():\n",
    "    def __init__(self,mode):\n",
    "        if mode == 1:\n",
    "            self.sum = sumA\n",
    "        if mode == 2:\n",
    "            self.sum = sumB\n",
    "\n",
    "a = A(2)\n",
    "\n",
    "c = a.sum(1,2)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.16 ('GYM')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "885ba80e3279e9342e7dd7c1f03a1cf54dcbcf219785bf65aec8a278e13e1341"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
